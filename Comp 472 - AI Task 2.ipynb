{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60c819e",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75f80972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e094907c",
   "metadata": {},
   "source": [
    "2. Load the dataset in Python (you can use pandas.read csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a408ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>11.567</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>12.006</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>52</td>\n",
       "      <td>M</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>9.894</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>14.020</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11.349</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0     23   F    HIGH        HIGH   25.355  drugY\n",
       "1     47   M     LOW        HIGH   13.093  drugC\n",
       "2     47   M     LOW        HIGH   10.114  drugC\n",
       "3     28   F  NORMAL        HIGH    7.798  drugX\n",
       "4     61   F     LOW        HIGH   18.043  drugY\n",
       "..   ...  ..     ...         ...      ...    ...\n",
       "195   56   F     LOW        HIGH   11.567  drugC\n",
       "196   16   M     LOW        HIGH   12.006  drugC\n",
       "197   52   M  NORMAL        HIGH    9.894  drugX\n",
       "198   23   M  NORMAL      NORMAL   14.020  drugX\n",
       "199   40   F     LOW      NORMAL   11.349  drugX\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('drug200.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3309e88",
   "metadata": {},
   "source": [
    "\n",
    "3. Plot the distribution of the instances in each class and store the graphic in a file called drug-distribution.pdf. You can use matplotlib.pyplot. This pre-analysis will allow you to determine if the classes are balanced,and which metric is more appropriate to use to evaluate the performance of your classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e410f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=np.array(df['Drug'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f2accf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "instances=[None] * len(classes)\n",
    "index=0\n",
    "for drug in classes:\n",
    "    instances[index]=np.array(len(df['Drug'].loc[df['Drug']==drug]))\n",
    "    index+=1\n",
    "    \n",
    "drugFig = plt.figure()\n",
    "plt.bar(classes,instances)\n",
    "drugFig.savefig('drug-distribution.pdf', dpi=drugFig.dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8414674",
   "metadata": {},
   "source": [
    "4. Convert all ordinal and nominal features in numerical format. Make sure that your converted format respects the ordering of ordinal features, and does not introduce any ordering for nominal features. You may want to take a look at pandas.get dummies and pandas. Categorical to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1e4d25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>Age</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>NORMAL</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>NORMAL</th>\n",
       "      <th>Na_to_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F  M  Age  HIGH  LOW  NORMAL  HIGH  NORMAL  Na_to_K\n",
       "0  1  0   23     1    0       0     1       0   25.355\n",
       "1  0  1   47     0    1       0     1       0   13.093\n",
       "2  0  1   47     0    1       0     1       0   10.114\n",
       "3  1  0   28     0    0       1     1       0    7.798\n",
       "4  1  0   61     0    1       0     1       0   18.043"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sex = pd.get_dummies(df['Sex'])\n",
    "df_new = sex\n",
    "\n",
    "df_new = pd.concat([df_new, df['Age']], axis=1)\n",
    "\n",
    "bp = pd.get_dummies(df['BP'])\n",
    "df_new = pd.concat([df_new, bp], axis=1)\n",
    "\n",
    "chol = pd.get_dummies(df['Cholesterol'])\n",
    "df_new = pd.concat([df_new, chol], axis=1)\n",
    "\n",
    "df_new = pd.concat([df_new, df['Na_to_K']], axis=1)\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9559b2",
   "metadata": {},
   "source": [
    "5. Split the dataset using train test split using the default parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b1d2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_new\n",
    "y=df['Drug']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b430c33",
   "metadata": {},
   "source": [
    "\n",
    "6. Run 6 different classifiers:\n",
    "\n",
    "(a) NB: a Gaussian Naive Bayes Classifier (naive bayes.GaussianNB) with the default parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5de7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "nb_prediction = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f90cf7e",
   "metadata": {},
   "source": [
    "(b) Base-DT: a Decision Tree (tree.DecisionTreeClassifier) with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21790b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dclf = DecisionTreeClassifier()\n",
    "dclf.fit(X_train, y_train)\n",
    "dt_prediction = dclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53000ca8",
   "metadata": {},
   "source": [
    "(c) Top-DT: a better performing Decision Tree found using (GridSearchCV). The gridsearch will allow you to find the best combination of hyper-parameters, as determined by the evaluation function that you have determined in step (3) above. The hyper-parameters that you will experiment with are:\n",
    "- criterion: gini or entropy\n",
    "- max depth : 2 different values of your choice\n",
    "- min samples split: 3 different values of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "feb4af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['drugY', 'drugY', 'drugB', 'drugY', 'drugY', 'drugY', 'drugX',\n",
       "       'drugY', 'drugY', 'drugX', 'drugY', 'drugB', 'drugX', 'drugX',\n",
       "       'drugX', 'drugB', 'drugY', 'drugY', 'drugY', 'drugX', 'drugY',\n",
       "       'drugX', 'drugX', 'drugB', 'drugX', 'drugY', 'drugA', 'drugX',\n",
       "       'drugX', 'drugA', 'drugC', 'drugA', 'drugY', 'drugY', 'drugB',\n",
       "       'drugX', 'drugY', 'drugY', 'drugC', 'drugX'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "              'criterion': ['entropy'],\n",
    "              'max_depth': [2,4], \n",
    "              'min_samples_split': [3,4,5],\n",
    "             }\n",
    "\n",
    "grid_obj = GridSearchCV(DecisionTreeClassifier(), parameters)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "t_dt_prediction = clf.predict(X_test)\n",
    "print(grid_obj.best_params_)\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d254bdd",
   "metadata": {},
   "source": [
    "(d) PER: a Perceptron (linear model.Perceptron), with default parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fb20329",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "Perceptron()\n",
    "per_prediction=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465e53e1",
   "metadata": {},
   "source": [
    "(e) Base-MLP: a Multi-Layered Perceptron (neural network.MLPClassifier) with 1 hidden layer of 100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2fb657f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drugY', 'drugY', 'drugX', 'drugY', 'drugX', 'drugY', 'drugX',\n",
       "       'drugY', 'drugY', 'drugX', 'drugX', 'drugX', 'drugX', 'drugX',\n",
       "       'drugX', 'drugX', 'drugY', 'drugY', 'drugY', 'drugX', 'drugY',\n",
       "       'drugX', 'drugX', 'drugX', 'drugX', 'drugY', 'drugX', 'drugX',\n",
       "       'drugX', 'drugX', 'drugX', 'drugY', 'drugY', 'drugY', 'drugX',\n",
       "       'drugX', 'drugY', 'drugY', 'drugY', 'drugY'], dtype='<U5')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', solver='sgd', max_iter=3000)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "mlp_prediction=mlp_clf.predict(X_test)\n",
    "mlp_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2705383",
   "metadata": {},
   "source": [
    "(f) Top-MLP: a better performing Multi-Layered Perceptron found using grid search. For this, you need to experiment with the following parameter values:\n",
    "- activation function: sigmoid, tanh, relu and identity\n",
    "- 2 network architectures of your choice: for eg 2 hidden layers with 30 + 50 nodes, 3 hidden layers with 10 + 10 + 10\n",
    "- solver: Adam and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7da3edcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'max_iter': 10000, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(30,50), (10,10,10)],\n",
    "    'activation': ['tanh', 'relu', 'identity'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'max_iter':[10000]\n",
    "}\n",
    "grid = GridSearchCV(MLPClassifier(), param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "t_mlp_prediction=grid.predict(X_test)\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17453f1",
   "metadata": {},
   "source": [
    "7. For each of the 6 classifier above, append the following information in a file called drugs-performance.txt:\n",
    "(to make it easier for the TAs, make sure that your output for each sub-question below is clearly marked\n",
    "in your output file, using the headings (a), (b) . .. )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374cba22",
   "metadata": {},
   "source": [
    "(b) the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97533810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  0  0  0  0]\n",
      " [ 0  5  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  0 13  0]\n",
      " [ 3  1  2  2  9]]\n",
      "[[ 3  0  0  0  0]\n",
      " [ 0  5  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  0 13  0]\n",
      " [ 0  0  0  0 17]]\n",
      "[[ 3  0  0  0  0]\n",
      " [ 0  5  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  0 13  0]\n",
      " [ 0  0  0  0 17]]\n",
      "[[ 2  0  0  0  1]\n",
      " [ 2  3  0  0  0]\n",
      " [ 0  0  1  0  1]\n",
      " [ 2  3  7  0  1]\n",
      " [ 2  0  2  0 13]]\n",
      "[[ 0  0  0  2  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  0  1  1]\n",
      " [ 0  0  0 12  1]\n",
      " [ 0  0  0  2 15]]\n",
      "[[ 3  0  0  0  0]\n",
      " [ 0  5  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  0 13  0]\n",
      " [ 0  1  0  0 16]]\n"
     ]
    }
   ],
   "source": [
    "nb_cmatrix = confusion_matrix(y_test, nb_prediction)\n",
    "dt_cmatrix = confusion_matrix(y_test, dt_prediction)\n",
    "t_dt_cmatrix = confusion_matrix(y_test, t_dt_prediction)\n",
    "per_cmatrix = confusion_matrix(y_test, per_prediction)\n",
    "mlp_cmatrix = confusion_matrix(y_test, mlp_prediction)\n",
    "t_mlp_cmatrix = confusion_matrix(y_test, t_mlp_prediction)\n",
    "print(nb_cmatrix)\n",
    "print(dt_cmatrix)\n",
    "print(t_dt_cmatrix)\n",
    "print(per_cmatrix)\n",
    "print(mlp_cmatrix)\n",
    "print(t_mlp_cmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41994e1c",
   "metadata": {},
   "source": [
    "(c) the precision, recall, and F1-measure for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "301ed354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugY       0.50      1.00      0.67         3\n",
      "       drugC       0.83      1.00      0.91         5\n",
      "       drugX       0.50      1.00      0.67         2\n",
      "       drugA       0.87      1.00      0.93        13\n",
      "       drugB       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.80        40\n",
      "   macro avg       0.74      0.91      0.77        40\n",
      "weighted avg       0.87      0.80      0.79        40\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugY       1.00      1.00      1.00         3\n",
      "       drugC       1.00      1.00      1.00         5\n",
      "       drugX       1.00      1.00      1.00         2\n",
      "       drugA       1.00      1.00      1.00        13\n",
      "       drugB       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugY       1.00      1.00      1.00         3\n",
      "       drugC       1.00      1.00      1.00         5\n",
      "       drugX       1.00      1.00      1.00         2\n",
      "       drugA       1.00      1.00      1.00        13\n",
      "       drugB       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugY       0.25      0.67      0.36         3\n",
      "       drugC       0.50      0.60      0.55         5\n",
      "       drugX       0.10      0.50      0.17         2\n",
      "       drugA       0.00      0.00      0.00        13\n",
      "       drugB       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.48        40\n",
      "   macro avg       0.33      0.51      0.37        40\n",
      "weighted avg       0.43      0.47      0.44        40\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugY       0.00      0.00      0.00         3\n",
      "       drugC       0.00      0.00      0.00         5\n",
      "       drugX       0.00      0.00      0.00         2\n",
      "       drugA       0.55      0.92      0.69        13\n",
      "       drugB       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.68        40\n",
      "   macro avg       0.28      0.36      0.31        40\n",
      "weighted avg       0.53      0.68      0.59        40\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugY       1.00      1.00      1.00         3\n",
      "       drugC       0.83      1.00      0.91         5\n",
      "       drugX       1.00      1.00      1.00         2\n",
      "       drugA       1.00      1.00      1.00        13\n",
      "       drugB       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.97      0.99      0.98        40\n",
      "weighted avg       0.98      0.97      0.98        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wi151\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wi151\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wi151\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wi151\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wi151\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wi151\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "nb_classificationReport = classification_report(y_test, nb_prediction, target_names=classes)\n",
    "dt_classificationReport = classification_report(y_test, dt_prediction, target_names=classes)\n",
    "t_dt_classificationReport = classification_report(y_test, t_dt_prediction, target_names=classes)\n",
    "per_classificationReport = classification_report(y_test, per_prediction, target_names=classes)\n",
    "mlp_classificationReport = classification_report(y_test, mlp_prediction, target_names=classes)\n",
    "t_mlp_classificationReport = classification_report(y_test, t_mlp_prediction, target_names=classes)\n",
    "print(nb_classificationReport)\n",
    "print(dt_classificationReport)\n",
    "print(t_dt_classificationReport)\n",
    "print(per_classificationReport)\n",
    "print(mlp_classificationReport)\n",
    "print(t_mlp_classificationReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd2826",
   "metadata": {},
   "source": [
    "(d) the accuracy, macro-average F1 and weighted-average F1 of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38412553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.8 0.7726606726606727 0.7929861804861804\n",
      "DT: 1.0 1.0 1.0\n",
      "Top-DT: 1.0 1.0 1.0\n",
      "Top-MLP: 0.975 0.9757575757575758 0.9757575757575758\n",
      "PER: 0.475 0.37272727272727274 0.43863636363636366\n",
      "MLP: 0.675 0.30857142857142855 0.5871428571428571\n"
     ]
    }
   ],
   "source": [
    "nb_accuracyScore = accuracy_score(y_test, nb_prediction)\n",
    "nb_macroF1Score = f1_score(y_test, nb_prediction, average='macro')\n",
    "nb_weightedF1Score = f1_score(y_test, nb_prediction, average='weighted')\n",
    "print('NB:',nb_accuracyScore, nb_macroF1Score, nb_weightedF1Score)\n",
    "\n",
    "dt_accuracyScore = accuracy_score(y_test, dt_prediction)\n",
    "dt_macroF1Score = f1_score(y_test, dt_prediction, average='macro')\n",
    "dt_weightedF1Score = f1_score(y_test, dt_prediction, average='weighted')\n",
    "print('DT:', dt_accuracyScore, dt_macroF1Score, dt_weightedF1Score)\n",
    "\n",
    "t_dt_accuracyScore = accuracy_score(y_test, t_dt_prediction)\n",
    "t_dt_macroF1Score = f1_score(y_test, t_dt_prediction, average='macro')\n",
    "t_dt_weightedF1Score = f1_score(y_test, t_dt_prediction, average='weighted')\n",
    "print('Top-DT:',t_dt_accuracyScore, t_dt_macroF1Score, t_dt_weightedF1Score)\n",
    "\n",
    "t_mlp_accuracyScore = accuracy_score(y_test, t_mlp_prediction)\n",
    "t_mlp_macroF1Score = f1_score(y_test, t_mlp_prediction, average='macro')\n",
    "t_mlp_weightedF1Score = f1_score(y_test, t_mlp_prediction, average='weighted')\n",
    "print('Top-MLP:', t_mlp_accuracyScore, t_mlp_macroF1Score, t_mlp_weightedF1Score)\n",
    "\n",
    "per_accuracyScore = accuracy_score(y_test, per_prediction)\n",
    "per_macroF1Score = f1_score(y_test, per_prediction, average='macro')\n",
    "per_weightedF1Score = f1_score(y_test, per_prediction, average='weighted')\n",
    "print('PER:',per_accuracyScore, per_macroF1Score, per_weightedF1Score)\n",
    "\n",
    "mlp_accuracyScore = accuracy_score(y_test, mlp_prediction)\n",
    "mlp_macroF1Score = f1_score(y_test, mlp_prediction, average='macro')\n",
    "mlp_weightedF1Score = f1_score(y_test, mlp_prediction, average='weighted')\n",
    "print('MLP:', mlp_accuracyScore, mlp_macroF1Score, mlp_weightedF1Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8082457",
   "metadata": {},
   "source": [
    "Write to `drug-performance.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "951ab10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('drug-performance.txt', 'w')\n",
    "f.write('Gaussian Naive Bayes Classifier with default paramaters\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('b) Confusion matrix\\n')\n",
    "f.write(pd.DataFrame(nb_cmatrix).to_string() + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('c) Classification Report\\n\\n')\n",
    "f.write(nb_classificationReport + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('d) Accuracy, Macro Average F1, Weighted Average\\n')\n",
    "f.write('accuracy: ' + str(nb_accuracyScore) + '\\n')\n",
    "f.write('macro average f1: ' + str(nb_macroF1Score) + '\\n')\n",
    "f.write('weighted average: ' + str(nb_weightedF1Score) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('\\n\\n')\n",
    "f.write('Decision Tree with default parameters\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('b) Confusion matrix\\n')\n",
    "f.write(pd.DataFrame(dt_cmatrix).to_string() + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('c) Classification Report\\n\\n')\n",
    "f.write(dt_classificationReport + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('d) Accuracy, Macro Average F1, Weighted Average\\n')\n",
    "f.write('accuracy: ' + str(dt_accuracyScore) + '\\n')\n",
    "f.write('macro average f1: ' + str(dt_macroF1Score) + '\\n')\n",
    "f.write('weighted average: ' + str(dt_weightedF1Score) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('\\n\\n')\n",
    "f.write('Top-DT with the following parameters\\n')\n",
    "f.write('- criterion: entropy\\n')\n",
    "f.write('- max depth : [2,4]\\n')\n",
    "f.write('- min samples split: [3,4,5]\\n')\n",
    "f.write('- Best params from GridSearchCV:' + str(grid_obj.best_params_) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('b) Confusion matrix\\n')\n",
    "f.write(pd.DataFrame(t_dt_cmatrix).to_string() + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('c) Classification Report\\n\\n')\n",
    "f.write(t_dt_classificationReport + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('d) Accuracy, Macro Average F1, Weighted Average\\n')\n",
    "f.write('accuracy: ' + str(t_dt_accuracyScore) + '\\n')\n",
    "f.write('macro average f1: ' + str(t_dt_macroF1Score) + '\\n')\n",
    "f.write('weighted average: ' + str(t_dt_weightedF1Score) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('\\n\\n')\n",
    "f.write('Perceptron with default parameter values\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('b) Confusion matrix\\n')\n",
    "f.write(pd.DataFrame(per_cmatrix).to_string() + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('c) Classification Report\\n\\n')\n",
    "f.write(per_classificationReport + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('d) Accuracy, Macro Average F1, Weighted Average\\n')\n",
    "f.write('accuracy: ' + str(per_accuracyScore) + '\\n')\n",
    "f.write('macro average f1: ' + str(per_macroF1Score) + '\\n')\n",
    "f.write('weighted average: ' + str(per_weightedF1Score) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('\\n\\n')\n",
    "f.write('Multi-Layered Perceptron \\n- 1 hidden layer of 100 neurons \\n- logistic\\n- stochastic gradient descent\\n- default values for the rest of the parameters.\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('b) Confusion matrix\\n')\n",
    "f.write(pd.DataFrame(mlp_cmatrix).to_string() + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('c) Classification Report\\n\\n')\n",
    "f.write(mlp_classificationReport + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('d) Accuracy, Macro Average F1, Weighted Average\\n')\n",
    "f.write('accuracy: ' + str(mlp_accuracyScore) + '\\n')\n",
    "f.write('macro average f1: ' + str(mlp_macroF1Score) + '\\n')\n",
    "f.write('weighted average: ' + str(mlp_weightedF1Score) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('\\n\\n')\n",
    "f.write('Top-MLP\\n')\n",
    "f.write('- activation function: sigmoid, tanh, relu and identity\\n')\n",
    "f.write('- 2 network architectures of your choice: 2 hidden layers with 30 + 50 nodes, \\n- 3 hidden layers with 10 + 10 + 10\\n')\n",
    "f.write('- solver: Adam and stochastic gradient descent\\n')\n",
    "f.write('- Best params from GridSearchCV: ' + str(grid.best_params_) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('b) Confusion matrix\\n')\n",
    "f.write(pd.DataFrame(t_mlp_cmatrix).to_string() + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('c) Classification Report\\n\\n')\n",
    "f.write(t_mlp_classificationReport + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('d) Accuracy, Macro Average F1, Weighted Average\\n')\n",
    "f.write('accuracy: ' + str(t_mlp_accuracyScore) + '\\n')\n",
    "f.write('macro average f1: ' + str(t_mlp_macroF1Score) + '\\n')\n",
    "f.write('weighted average: ' + str(t_mlp_weightedF1Score) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ec738d",
   "metadata": {},
   "source": [
    "8. Redo steps 6, 10 times for each model and append the average accuracy, average macro-average F1, average weighted-average F1 as well as the standard deviation for the accuracy, the standard deviation of the macro-average F1, and the standard deviation of the weighted-average F1 at the end of the file drugs-performance.txt. Does the same model give you the same performance every time? Explain in a plain text file called drugs-discussion.txt. A 1 or 2 paragraph discussion is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00d99f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_accuracies = []\n",
    "gnb_macro_f1s = []\n",
    "gnb_weighted_f1s = []\n",
    "\n",
    "for n in range(10):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    gnb_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    gnb_macro_f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    gnb_weighted_f1s.append(f1_score(y_test, y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037d69e",
   "metadata": {},
   "source": [
    "(b) Base-DT: a Decision Tree (tree.DecisionTreeClassifier) with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea81991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dclf_accuracies = []\n",
    "dclf_macro_f1s = []\n",
    "dclf_weighted_f1s = []\n",
    "\n",
    "for n in range(10):\n",
    "    dclf = DecisionTreeClassifier(random_state=n)\n",
    "    dclf.fit(X_train, y_train)\n",
    "    val_pred = dclf.predict(X_test)\n",
    "    dclf_accuracies.append(accuracy_score(y_test, val_pred))\n",
    "    dclf_macro_f1s.append(f1_score(y_test, val_pred, average='macro'))\n",
    "    dclf_weighted_f1s.append(f1_score(y_test, val_pred, average='weighted'))\n",
    "    \n",
    "dclf_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671eb27f",
   "metadata": {},
   "source": [
    "(c) Top-DT: a better performing Decision Tree found using (GridSearchCV). The gridsearch will allow you to find the best combination of hyper-parameters, as determined by the evaluation function that you have determined in step (3) above. The hyper-parameters that you will experiment with are:\n",
    "\n",
    "- criterion: gini or entropy\n",
    "- max depth : 2 different values of your choice\n",
    "- min samples split: 3 different values of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ec5bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dt_accuracies = []\n",
    "t_dt_macro_f1s = []\n",
    "t_dt_weighted_f1s = []\n",
    "    \n",
    "parameters = {\n",
    "              'criterion': ['entropy'],\n",
    "              'max_depth': [2,4], \n",
    "              'min_samples_split': [3,4,5],\n",
    "             }\n",
    "\n",
    "for n in range(10):\n",
    "    grid_obj = GridSearchCV(DecisionTreeClassifier(), parameters)\n",
    "    grid_obj = grid_obj.fit(X_train, y_train)\n",
    "    clf = grid_obj.best_estimator_\n",
    "    clf.fit(X_train, y_train)\n",
    "    t_dt_prediction = clf.predict(X_test)\n",
    "    t_dt_accuracies.append(accuracy_score(y_test, t_dt_prediction))\n",
    "    t_dt_macro_f1s.append(f1_score(y_test, t_dt_prediction, average='macro'))\n",
    "    t_dt_weighted_f1s.append(f1_score(y_test, t_dt_prediction, average='weighted'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd369763",
   "metadata": {},
   "source": [
    "(d) PER: a Perceptron (linear model.Perceptron), with default parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25a482b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_accuracies = []\n",
    "perc_macro_f1s = []\n",
    "perc_weighted_f1s = []\n",
    "\n",
    "for n in range(10):\n",
    "    clf = Perceptron()\n",
    "    clf.fit(X_train, y_train)\n",
    "    Perceptron()\n",
    "    predictions = clf.predict(X_test)\n",
    "    perc_accuracies.append(accuracy_score(y_test, predictions))\n",
    "    perc_macro_f1s.append(f1_score(y_test, predictions, average='macro'))\n",
    "    perc_weighted_f1s.append(f1_score(y_test, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa2f26",
   "metadata": {},
   "source": [
    "(e) Base-MLP: a Multi-Layered Perceptron (neural network.MLPClassifier) with 1 hidden layer of 100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b581df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_accuracies = []\n",
    "mlp_macro_f1s = []\n",
    "mlp_weighted_f1s = []\n",
    "\n",
    "for n in range(10):\n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', solver='sgd', max_iter=3000)\n",
    "    mlp_clf.fit(X_train, y_train)\n",
    "    predictions=mlp_clf.predict(X_test)\n",
    "    mlp_accuracies.append(accuracy_score(y_test, predictions))\n",
    "    mlp_macro_f1s.append(f1_score(y_test, predictions, average='macro'))\n",
    "    mlp_weighted_f1s.append(f1_score(y_test, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f2d2e",
   "metadata": {},
   "source": [
    "(f) Top-MLP: a better performing Multi-Layered Perceptron found using grid search. For this, you need to experiment with the following parameter values:\n",
    "- activation function: sigmoid, tanh, relu and identity\n",
    "- 2 network architectures of your choice: for eg 2 hidden layers with 30 + 50 nodes, 3 hidden layers with 10 + 10 + 10\n",
    "- solver: Adam and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "903ff9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_accuracies = []\n",
    "grid_macro_f1s = []\n",
    "grid_weighted_f1s = []\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(30,50), (10,10,10)],\n",
    "    'activation': ['tanh', 'relu', 'identity'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'max_iter':[10000]\n",
    "}\n",
    "\n",
    "for n in range(10):\n",
    "    grid = GridSearchCV(MLPClassifier(), param_grid)\n",
    "    grid.fit(X_train, y_train)\n",
    "    predictions=grid.predict(X_test)\n",
    "    grid_accuracies.append(accuracy_score(y_test, predictions))\n",
    "    grid_macro_f1s.append(f1_score(y_test, predictions, average='macro'))\n",
    "    grid_weighted_f1s.append(f1_score(y_test, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f09b29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.write('\\n\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('Average Metrics Over 10 passes of each model\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('Gaussian Naive Bayes Classifier with default paramaters\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('Accuracies: ' + str(gnb_accuracies) + '\\n')\n",
    "f.write('Average Accuracy: ' + str(np.average(gnb_accuracies)) + '\\n')\n",
    "f.write('Accuracy Standard Deviation: ' + str(np.std(gnb_accuracies)) + '\\n')\n",
    "f.write('Macro F1 Scores: ' + str(gnb_macro_f1s) + '\\n')\n",
    "f.write('Average Macro F1 Score: ' + str(np.average(gnb_macro_f1s)) + '\\n')\n",
    "f.write('Macro F1 Standard Deviation: ' + str(np.std(gnb_macro_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Scores: ' + str(gnb_weighted_f1s) + '\\n')\n",
    "f.write('Average Weighted F1 Score: ' + str(np.average(gnb_weighted_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Score Standard Deviation: ' + str(np.std(gnb_weighted_f1s)) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('\\n\\n')\n",
    "f.write('Decision Tree with default parameters\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('Accuracies: ' + str(dclf_accuracies) + '\\n')\n",
    "f.write('Average Accuracy: ' + str(np.average(dclf_accuracies)) + '\\n')\n",
    "f.write('Accuracy Standard Deviation: ' + str(np.std(dclf_accuracies)) + '\\n')\n",
    "f.write('Macro F1 Scores: ' + str(dclf_macro_f1s) + '\\n')\n",
    "f.write('Average Macro F1 Score: ' + str(np.average(dclf_macro_f1s)) + '\\n')\n",
    "f.write('Macro F1 Standard Deviation: ' + str(np.std(dclf_macro_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Scores: ' + str(dclf_weighted_f1s) + '\\n')\n",
    "f.write('Average Weighted F1 Score: ' + str(np.average(dclf_weighted_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Score Standard Deviation: ' + str(np.std(dclf_weighted_f1s)) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')      \n",
    "f.write('\\n\\n')\n",
    "f.write('Top-DT with the following parameters\\n')\n",
    "f.write('- criterion: entropy\\n')\n",
    "f.write('- max depth : [2,4]\\n')\n",
    "f.write('- min samples split: [3,4,5]\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('Accuracies: ' + str(t_dt_accuracies) + '\\n')\n",
    "f.write('Average Accuracy: ' + str(np.average(t_dt_accuracies)) + '\\n')\n",
    "f.write('Accuracy Standard Deviation: ' + str(np.std(t_dt_accuracies)) + '\\n')\n",
    "f.write('Macro F1 Scores: ' + str(t_dt_macro_f1s) + '\\n')\n",
    "f.write('Average Macro F1 Score: ' + str(np.average(t_dt_macro_f1s)) + '\\n')\n",
    "f.write('Macro F1 Standard Deviation: ' + str(np.std(t_dt_macro_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Scores: ' + str(t_dt_weighted_f1s) + '\\n')\n",
    "f.write('Average Weighted F1 Score: ' + str(np.average(t_dt_weighted_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Score Standard Deviation: ' + str(np.std(t_dt_weighted_f1s)) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('\\n\\n')\n",
    "f.write('Perceptron with default parameter values\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('Accuracies: ' + str(perc_accuracies) + '\\n')\n",
    "f.write('Average Accuracy: ' + str(np.average(perc_accuracies)) + '\\n')\n",
    "f.write('Accuracy Standard Deviation: ' + str(np.std(perc_accuracies)) + '\\n')\n",
    "f.write('Macro F1 Scores: ' + str(perc_macro_f1s) + '\\n')\n",
    "f.write('Average Macro F1 Score: ' + str(np.average(perc_macro_f1s)) + '\\n')\n",
    "f.write('Macro F1 Standard Deviation: ' + str(np.std(perc_macro_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Scores: ' + str(perc_weighted_f1s) + '\\n')\n",
    "f.write('Average Weighted F1 Score: ' + str(np.average(perc_weighted_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Score Standard Deviation: ' + str(np.std(perc_weighted_f1s)) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n') \n",
    "f.write('\\n\\n')\n",
    "f.write('Multi-Layered Perceptron \\n- 1 hidden layer of 100 neurons \\n- logistic\\n- stochastic gradient descent\\n- default values for the rest of the parameters.\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('Accuracies: ' + str(mlp_accuracies) + '\\n')\n",
    "f.write('Average Accuracy: ' + str(np.average(mlp_accuracies)) + '\\n')\n",
    "f.write('Accuracy Standard Deviation: ' + str(np.std(mlp_accuracies)) + '\\n')\n",
    "f.write('Macro F1 Scores: ' + str(mlp_macro_f1s) + '\\n')\n",
    "f.write('Average Macro F1 Score: ' + str(np.average(mlp_macro_f1s)) + '\\n')\n",
    "f.write('Macro F1 Standard Deviation: ' + str(np.std(mlp_macro_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Scores: ' + str(mlp_weighted_f1s) + '\\n')\n",
    "f.write('Average Weighted F1 Score: ' + str(np.average(mlp_weighted_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Score Standard Deviation: ' + str(np.std(mlp_weighted_f1s)) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.write('\\n\\n')\n",
    "f.write('Top-MLP\\n')\n",
    "f.write('- activation function: sigmoid, tanh, relu and identity\\n')\n",
    "f.write('- 2 network architectures of your choice: 2 hidden layers with 30 + 50 nodes, \\n- 3 hidden layers with 10 + 10 + 10\\n')\n",
    "f.write('- solver: Adam and stochastic gradient descent\\n')\n",
    "f.write('Accuracies: ' + str(grid_accuracies) + '\\n')\n",
    "f.write('Average Accuracy: ' + str(np.average(grid_accuracies)) + '\\n')\n",
    "f.write('Accuracy Standard Deviation: ' + str(np.std(grid_accuracies)) + '\\n')\n",
    "f.write('Macro F1 Scores: ' + str(grid_macro_f1s) + '\\n')\n",
    "f.write('Average Macro F1 Score: ' + str(np.average(grid_macro_f1s)) + '\\n')\n",
    "f.write('Macro F1 Standard Deviation: ' + str(np.std(grid_macro_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Scores: ' + str(grid_weighted_f1s) + '\\n')\n",
    "f.write('Average Weighted F1 Score: ' + str(np.average(grid_weighted_f1s)) + '\\n')\n",
    "f.write('Weighted F1 Score Standard Deviation: ' + str(np.std(grid_weighted_f1s)) + '\\n')\n",
    "f.write('---------------------------------------------------------------------------------\\n')\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "110646fc04d8eb4b472f783b11b2cd66382864c9ecb559c878e82b087fcce6fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
